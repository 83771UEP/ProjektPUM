{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<PRE>\n",
    "█▀█ ▄▀█ █▄░█ █▀▄ █▀█ █▀▄▀█   █▀▀ █▀█ █▀█ █▀▀ █▀ ▀█▀   █▀▀ █░░ ▄▀█ █▀ █▀ █ █▀▀ █ █▀▀ █▀█\n",
    "█▀▄ █▀█ █░▀█ █▄▀ █▄█ █░▀░█   █▀░ █▄█ █▀▄ ██▄ ▄█ ░█░   █▄▄ █▄▄ █▀█ ▄█ ▄█ █ █▀░ █ ██▄ █▀▄\n",
    "</PRE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model lasy drzew decyzyjnych\n",
    "\n",
    "### 1. Argumenty za przyjęciem modelu lasu drzew decyzyjnych:\n",
    "- zdolność radzenia sobie z dużą liczbą cech\n",
    "- ddolność uwzględniania nieliniowych relacji\n",
    "- duża odporność na nadmierne dopasowanie\n",
    "- łatwość interpretacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import math\n",
    "import logging\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "# Data handling and visualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn libraries for preprocessing and metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, label_binarize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# Scikit-learn libraries for model selection\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate, train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Scikit-learn libraries for models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Scikit-learn libraries for pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Imbalanced-learn libraries\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deklaracja funkcji - pobranie i przeskalowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(scaler_type: Optional[str] = None) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \n",
    "    # Pobranie danych z plików .csv\n",
    "    X = pd.read_csv('wineData.csv')\n",
    "    y = pd.read_csv('wineRatings.csv')\n",
    "    y = y.values.ravel()\n",
    "    \n",
    "    #Informacje o danych do logów\n",
    "    logging.info(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    #Przeskalowanie danych przy użyciu obiektu MinMaxScaler\n",
    "    if scaler_type in [\"minmax\", \"standard\"]:\n",
    "        scaler = MinMaxScaler() if scaler_type == \"minmax\" else StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        logging.info(f\"Data scaled using {scaler_type} scaler.\")\n",
    "    else:\n",
    "        logging.info(\"No scaling applied.\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deklaracja funkcji - podział danych, uczenie, hiperparametryzacja i ocena modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcja definiująca strategię próbkowania\n",
    "def sampling_strategy(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    max_count = max(counts)\n",
    "    return {class_label: max(int(0.40 * max_count), count) for class_label, count in zip(unique, counts)}\n",
    "\n",
    "#Funkcja dzieląca dane na zbiór treningowy i testowy oraz nakladająca oversampler\n",
    "def initialize_and_split_data(scaler_type: str, method: str = 'none') -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    X, y = initialize_data(scaler_type)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    if method == 'smote':\n",
    "        strategy = sampling_strategy(y_train)\n",
    "        oversampler = SMOTE(sampling_strategy=strategy, k_neighbors=2, random_state=42)\n",
    "        X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "        logging.info(f\"Applied {method} to handle class imbalance in the training data.\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#Funkcja ewaluująca model\n",
    "def cross_validation_and_evaluation(X_train: np.ndarray, y_train: np.ndarray, model: Any, best_params: Dict[str, Any], cv_splits: int = 5, random_state: int = 42) -> Tuple[float, np.ndarray, np.ndarray, np.ndarray, list, Dict[str, Any]]:\n",
    "    # Set the best parameters for the model\n",
    "    model.set_params(**best_params)\n",
    "    pipe = make_pipeline(model)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    kfold = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "    cv_results = cross_validate(pipe, X_train, y_train, cv=kfold, return_train_score=True)\n",
    "    logging.info(f\"Cross-validation results: {cv_results}\")\n",
    "\n",
    "\n",
    "    logging.info(f\"Mean accuracy score over all folds: {cv_results['test_score'].mean() * 100:.2f}%\")\n",
    "    logging.info(f\"Mean training accuracy score over all folds: {cv_results['train_score'].mean() * 100:.2f}%\")\n",
    "    return cv_results, cv_results['test_score'].mean()\n",
    "\n",
    "#Funkcja znajująca najlepsze hiperparametry\n",
    "def optimize_hyperparameters(estimator, X_train: np.ndarray, y_train: np.ndarray, param_grid: Dict[str, Any], n_iter: int = 20, cv_splits: int = 5, random_state: int = 42) -> Dict[str, Any]:\n",
    "    random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, n_iter=n_iter, cv= cv_splits, scoring='accuracy', random_state=random_state, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    logging.info(f\"Best accuracy score: {random_search.best_score_ * 100:.2f}%\")\n",
    "    logging.info(f\"Best parameters: {random_search.best_params_}\")\n",
    "    return random_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deklaracja funkcji - generacja wykresów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(y_test: Any, y_pred: Any) -> Dict[str, Any]:\n",
    "    # Determine unique classes\n",
    "    classes = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "    report = classification_report(y_test, y_pred, labels=classes, output_dict=True, zero_division=1)\n",
    "    logging.info(\"Classification report:\\n%s\", classification_report(y_test, y_pred, labels=classes, zero_division=1))\n",
    "    logging.info(\"Confusion matrix:\\n%s\", confusion_matrix(y_test, y_pred, labels=classes))\n",
    "    return report\n",
    "\n",
    "#Funkcja generująca histogram\n",
    "def plot_histogram(y_test: Any, y_pred: Any, ax: plt.Axes) -> None:\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).plot.hist(ax=ax, alpha=0.5)\n",
    "    ax.set_title('Actual vs Predicted values')\n",
    "    ax.set_xlabel('Values')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend(['Actual', 'Predicted'])\n",
    "\n",
    "#Funkcja generująca wykres przewidywań vs właściwych ocen wina\n",
    "def plot_actual_vs_predicted(y_test: Any, y_pred: Any, ax: plt.Axes) -> None:\n",
    "    pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).plot(ax=ax, marker='o')\n",
    "    ax.set_title('Actual vs Predicted values')\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.legend(['Actual', 'Predicted'])\n",
    "\n",
    "#Funkcja generująca raport klasyfikacji\n",
    "def plot_classification_report(report: Dict[str, Any], ax: plt.Axes) -> None:\n",
    "    report_df = pd.DataFrame(report).transpose().drop(columns='support')\n",
    "    report_df.plot(kind='bar', ax=ax)\n",
    "    ax.set_title('Classification Report Metrics')\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "#Funkcja generująca macierz pomyłek\n",
    "def plot_confusion_matrix(report: np.ndarray, classes: list, ax: plt.Axes) -> None:\n",
    "    sns.heatmap(report, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, ax=ax, cmap='Blues')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "#Funkcja wywołująca wszystkie wykesy\n",
    "def display_plots(y_fold_test: np.ndarray, y_pred: np.ndarray, report: Dict[str, Any], cv_results: Dict[str, Any], accuracy_without_optimization: float, accuracy_with_optimization: float) -> None:\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 16))\n",
    "    classes = [3, 4, 5, 6, 7, 8]\n",
    "    plot_actual_vs_predicted(y_fold_test, y_pred, axs[0, 0])\n",
    "    plot_confusion_matrix(confusion_matrix(y_fold_test, y_pred, labels=classes), classes, axs[0, 1])\n",
    "    plot_classification_report(report, axs[1, 0])\n",
    "    plot_histogram(y_fold_test, y_pred, axs[2, 1])\n",
    "    \n",
    "    axs[1, 1].plot(cv_results['test_score'], label='Test Score')\n",
    "    axs[1, 1].plot(cv_results['train_score'], label='Train Score')\n",
    "    axs[1, 1].set_title('Cross-validation Results with Optimized Hyperparameters')\n",
    "    axs[1, 1].set_xlabel('Fold Index')\n",
    "    axs[1, 1].set_ylabel('Accuracy')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    axs[2, 0].bar(['Without Optimization', 'With Optimization'], [accuracy_without_optimization, accuracy_with_optimization])\n",
    "    axs[2, 0].set_title('Comparison of Model Performance')\n",
    "    axs[2, 0].set_ylabel('Mean Accuracy Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Część głowna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 23:24:42,965 - INFO - X shape: (1503, 8), y shape: (1503,)\n",
      "2024-06-04 23:24:42,971 - INFO - Data scaled using standard scaler.\n",
      "2024-06-04 23:24:42,974 - ERROR - An error occurred during model evaluation and plotting.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bwojt\\AppData\\Local\\Temp\\ipykernel_12232\\2143759586.py\", line 4, in random_forest_main\n",
      "    X_train, X_test, y_train, y_test = initialize_and_split_data(\"standard\", 'smote')\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bwojt\\AppData\\Local\\Temp\\ipykernel_12232\\1631714562.py\", line 14, in initialize_and_split_data\n",
      "    X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bwojt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bwojt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 104, in fit_resample\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\bwojt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\multiclass.py\", line 221, in check_classification_targets\n",
      "    raise ValueError(\n",
      "ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def random_forest_main():\n",
    "    try:\n",
    "        #Podział danych na zbior testowy i treningowy\n",
    "        X_train, X_test, y_train, y_test = initialize_and_split_data(\"standard\", 'smote')\n",
    "        logging.info(\"Data initialization and splitting complete.\")\n",
    "\n",
    "        #Utworzenie obiektu modelu\n",
    "        rf = RandomForestClassifier()\n",
    "\n",
    "        #Wytrenowanie i wstepna ocena modelu\n",
    "        best_params = {}\n",
    "        cv_results, accuracy_without_optimization = cross_validation_and_evaluation(X_train, y_train, rf, best_params)\n",
    "\n",
    "        #Hiperparametryzacja\n",
    "        param_grid = {\n",
    "            'n_estimators': np.arange(50, 501, 50),  # number of trees in the forest\n",
    "            'max_depth': [None] + list(np.arange(10, 110, 10)),  # maximum depth of the tree\n",
    "            'min_samples_split': np.arange(2, 12, 2),  # minimum number of samples required to split an internal node\n",
    "            'min_samples_leaf': np.arange(1, 12, 2),  # minimum number of samples required to be at a leaf node\n",
    "            'max_features': ['sqrt', 'log2'],  # number of features to consider when looking for the best split\n",
    "            'bootstrap': [True, False]  # whether bootstrap samples are used when building trees\n",
    "        }\n",
    "        estimator = RandomForestClassifier()\n",
    "        best_params = optimize_hyperparameters(estimator, X_train, y_train, param_grid)\n",
    "\n",
    "        #Walidacja krzyżowa modelu ze zoptymalizowanymi hiperparametrami\n",
    "        cv_resultsOPT, accuracy_with_optimization = cross_validation_and_evaluation(X_train, y_train, rf, best_params)\n",
    "\n",
    "        #Ponowne wyktrenowanie modelu, ale ze zoptymalizowanymi hiperparametrami\n",
    "        rf.set_params(**best_params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        #Predykcje na zbiorze testowym\n",
    "        y_pred_optimized = rf.predict(X_test)\n",
    "\n",
    "        #Generacja raportu dla modelu\n",
    "        report_optimized = generate_report(y_test, y_pred_optimized)\n",
    "\n",
    "        #Generacja wykresów dla modelu\n",
    "        display_plots(y_test, y_pred_optimized, report_optimized, cv_resultsOPT, accuracy_without_optimization, accuracy_with_optimization)\n",
    "\n",
    "        #generacja wizualizacji lasu losowego\n",
    "        #Można odkomentować jeśli nie zależy na czasie (UWAGA: mi zawiesiło komputer)\n",
    "        #plot_forest(rf)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred during model evaluation and plotting.\", exc_info=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random_forest_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Podsumowanie\n",
    "\n",
    "Model wypada całkiem przyzwoicie, osiąga zdecydowanie najlepsze wyniki ze wszystkich rozpatrywanych. Jego dokładność oscyluje w okolicach 64-66%, a najgorzej radzi sobie z przewidywaniem mniej licznych klas, jednak nie ignoruje ich zupełnie. NIestety, model przejawia oznaki przetrenowania."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
